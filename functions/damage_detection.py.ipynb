{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### DEFINE MODEL ###\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(256, (3, 3), activation = 'relu',padding='same', input_shape = (28, 28,1)))\n",
    "model.add(Conv2D(512, (5, 5),padding='same', activation = 'relu'))\n",
    "model.add(Conv2D(256, (3, 3),padding='same', activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(784,activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "### CUSTOM LOSS - FOCAL LOSS\n",
    "\n",
    "def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        gamma=2.\n",
    "        alpha=.25\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        # Define epsilon so that the back-propagation will not result in NaN for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        # y_pred = y_pred + epsilon\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = tf.where(K.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true) * alpha\n",
    "        alpha_t = tf.where(K.equal(y_true, 1), alpha_factor, 1 - alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1 - p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.mean(K.sum(loss, axis=1))\n",
    "        return loss\n",
    "\n",
    "### METRICS ###\n",
    "\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "### CALLBACKS HERE ###\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,patience=2, min_lr=0.000000001)\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    print(np.sum(self.model.predict(x_train[0].reshape(1,28,28,1))))\n",
    "    display([x.reshape(28,28),x_label.reshape(28,28),self.model.predict(x.reshape(1,28,28,1)).reshape(28,28)])\n",
    " \n",
    "checkpoint = ModelCheckpoint(\"model.h5py\", monitor='loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', save_freq='epoch',period=1)\n",
    "\n",
    "### MODEL PARAMETERS ###\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9,\n",
    "    beta_2=0.999)\n",
    "\n",
    "lr_metric = get_lr_metric(optimizer)\n",
    "                              \n",
    "#if exists('model.h5py'):\n",
    "#  model.load_weights('model.h5py')\n",
    "# print('loaded stuff')\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = binary_focal_loss_fixed,\n",
    "              metrics = ['accuracy',lr_metric])\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs = 5, batch_size = 512,callbacks=[DisplayCallback(),reduce_lr,checkpoint],validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
